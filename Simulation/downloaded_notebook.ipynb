{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d535f696-6848-44de-8fe5-21f2e828e20e",
   "metadata": {},
   "source": [
    "# Simulate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12af317-b836-4d89-9830-d96985cdfe6c",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d842babb-df83-483d-84c6-f8f24a17e014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:48.174229Z",
     "iopub.status.busy": "2025-01-08T12:03:48.174229Z",
     "iopub.status.idle": "2025-01-08T12:03:49.952543Z",
     "shell.execute_reply": "2025-01-08T12:03:49.951536Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07968ae8-d7ff-43ea-a147-95cfe26d4a0b",
   "metadata": {},
   "source": [
    "## Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502d462f-85da-4ac1-9d19-fa2572dcc7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:49.955550Z",
     "iopub.status.busy": "2025-01-08T12:03:49.954539Z",
     "iopub.status.idle": "2025-01-08T12:03:49.961361Z",
     "shell.execute_reply": "2025-01-08T12:03:49.961361Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_gp_response(\n",
    "    likelihood_type=\"gaussian\", \n",
    "    sample_size=1000, \n",
    "    nugget=0.1, \n",
    "    marginal_variance=1.0, \n",
    "    custom_lengthscales=None, \n",
    "    seed=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate response and input variables from a Gaussian Process.\n",
    "\n",
    "    Parameters:\n",
    "    - likelihood_type: str, \"gaussian\" or \"bernoulli-logit\" for the likelihood.\n",
    "    - sample_size: int, number of samples to generate.\n",
    "    - nugget: float, noise variance (nugget).\n",
    "    - marginal_variance: float, marginal variance (outputscale).\n",
    "    - custom_lengthscale: list or tensor, custom length scales for each input dimension.\n",
    "    - seed: int, random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - X: torch.Tensor, input variables.\n",
    "    - sampled_field: torch.Tensor, simulated response.\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    # Step 1: Define the Gaussian Process Model\n",
    "    class ExactGPModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, train_x, train_y, likelihood):\n",
    "            super().__init__(train_x, train_y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[1])  # Enable ARD\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            mean_x = self.mean_module(x)\n",
    "            covar_x = self.covar_module(x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    # Step 2: Dummy Training Data\n",
    "    train_x = torch.rand(100, custom_lengthscales.shape[1])  # Small dummy train set\n",
    "    train_y = torch.zeros(100)    # Dummy target values\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        \n",
    "    model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "    # Step 3: Set Custom Length Scales\n",
    "    model.covar_module.base_kernel.lengthscale = custom_lengthscales\n",
    "\n",
    "    # Adjust Marginal Variance (Outputscale)\n",
    "    model.covar_module.outputscale = marginal_variance\n",
    "\n",
    "    # Adjust Nugget (Noise Variance)\n",
    "    if nugget is not None and likelihood_type == \"gaussian\":\n",
    "        likelihood.noise = nugget  \n",
    "\n",
    "    # Step 4: Switch to Evaluation Mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Step 5: Generate a Large Input Dataset\n",
    "    n_points = sample_size  # Large dataset\n",
    "    input_dim = custom_lengthscales.shape[1]\n",
    "    X = torch.rand(n_points, input_dim)\n",
    "\n",
    "    # Step 6: Sample from the GP Prior Without Constructing Full Covariance\n",
    "    with torch.no_grad():\n",
    "        latent_values = model(X).sample()\n",
    "\n",
    "        if likelihood_type == \"gaussian\":\n",
    "            sampled_field = latent_values\n",
    "            probs = None  # No probabilities for Gaussian\n",
    "        elif likelihood_type == \"bernoulli-logit\":\n",
    "            # Convert latent values to probabilities using the sigmoid function\n",
    "            probs = torch.sigmoid(latent_values)\n",
    "            # Simulate binary responses based on probabilities\n",
    "            sampled_field = torch.bernoulli(probs)\n",
    "        else:\n",
    "            raise ValueError(\"likelihood_type must be 'gaussian' or 'bernoulli-logit'.\")\n",
    "        \n",
    "    return X, sampled_field, probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a4fb1-c008-49cc-a3df-324a85421048",
   "metadata": {},
   "source": [
    "## Examples with plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2ec824-9a53-4bdf-9bf3-df99e9afa63b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:49.963366Z",
     "iopub.status.busy": "2025-01-08T12:03:49.963366Z",
     "iopub.status.idle": "2025-01-08T12:03:49.966030Z",
     "shell.execute_reply": "2025-01-08T12:03:49.966030Z"
    }
   },
   "outputs": [],
   "source": [
    "example = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6e44c-5caf-4e94-a03e-f941c2d7e1da",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c3177c-99c2-4f04-b0a4-64ec96022fcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:49.968036Z",
     "iopub.status.busy": "2025-01-08T12:03:49.968036Z",
     "iopub.status.idle": "2025-01-08T12:03:49.972721Z",
     "shell.execute_reply": "2025-01-08T12:03:49.972721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if example:\n",
    "    X, y, _ = simulate_gp_response(\"gaussian\",10000, 0.3, 1.0, torch.tensor([(0.25, 0.50,0.75,1.00,1.25)]),1)\n",
    "\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "    # Convert to numpy for easier plotting\n",
    "    X_np = X\n",
    "    y_np = y\n",
    "\n",
    "    # Calculate the number of rows and columns for the subplot grid\n",
    "    n_features = X_np.shape[1]\n",
    "    n_rows = int(np.ceil(n_features / 1))\n",
    "    n_cols = min(n_features, 1)\n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "    # Flatten the axs array for easier indexing\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Create scatter plots for each input dimension\n",
    "    for i in range(n_features):\n",
    "        axs[i].scatter(X_np[:, i], y_np, alpha=0.5)\n",
    "        axs[i].set_xlabel(f'Input Dimension {i+1}')\n",
    "        axs[i].set_ylabel('Response')\n",
    "        axs[i].set_title(f'Input Dim {i+1} vs Response')\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(n_features, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bccc21-4b9e-4d8a-8565-4a910832887c",
   "metadata": {},
   "source": [
    "### Bernoulli-logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9d4eec-4c16-4283-bfd8-76af061a8bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:49.974730Z",
     "iopub.status.busy": "2025-01-08T12:03:49.974730Z",
     "iopub.status.idle": "2025-01-08T12:03:49.979290Z",
     "shell.execute_reply": "2025-01-08T12:03:49.979290Z"
    }
   },
   "outputs": [],
   "source": [
    "if example:\n",
    "    X, y, b = simulate_gp_response(\"bernoulli-logit\",10000, 0, 1.0, torch.tensor([(0.25, 0.50,0.75,1.00,1.25)]),1)\n",
    "\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "    # Convert to numpy for easier plotting\n",
    "    X_np = X\n",
    "    y_binary_np = y\n",
    "    y_np = b\n",
    "\n",
    "    # Calculate the number of rows and columns for the subplot grid\n",
    "    n_features = X_np.shape[1]\n",
    "    n_rows = int(np.ceil(n_features / 1))\n",
    "    n_cols = min(n_features, 1)\n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "    # Flatten the axs array for easier indexing\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Create scatter plots for each input dimension\n",
    "    for i in range(n_features):\n",
    "        axs[i].scatter(X_np[:, i], y_np, alpha=0.5)\n",
    "        axs[i].set_xlabel(f'Input Dimension {i+1}')\n",
    "        axs[i].set_ylabel('Response')\n",
    "        axs[i].set_title(f'Input Dim {i+1} vs Response')\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(n_features, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
